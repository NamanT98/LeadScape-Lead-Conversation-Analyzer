{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_list(path):\n",
    "    data_entries = []\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for i in range(len(data['data'])):\n",
    "            row_entry = data['data'][i]\n",
    "            try:\n",
    "                row_specific_list = []\n",
    "                for dict in row_entry:\n",
    "                    for key in dict.keys():\n",
    "                        statement = str(key) +\" : \" + str(dict[key])\n",
    "                        row_specific_list.append(statement)\n",
    "                data_entries.append(row_specific_list)\n",
    "            except Exception as err:\n",
    "                new_row_entry = row_entry[\"conversations\"]\n",
    "                row_specific_list = []\n",
    "                for dict in new_row_entry:\n",
    "                    for key in dict.keys():\n",
    "                        statement = str(key) +\" : \" + str(dict[key])\n",
    "                        row_specific_list.append(statement)\n",
    "                data_entries.append(row_specific_list)\n",
    "    return data_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_summary_list(data, tokenizer, model):\n",
    "    summary_entries = []\n",
    "    for index in tqdm(range(0, 550),\"Completed\"):\n",
    "        conversations = data[index]\n",
    "        input_text = \" \".join(conversations)\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=350,  # Adjust depending on the desired summary length\n",
    "            min_length=40,   # Minimum length of the summary\n",
    "            num_beams=4,     # Number of beams for beam search\n",
    "            length_penalty=2.0\n",
    "            \n",
    "        )\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summary_entries.append(summary)\n",
    "    print(len(summary_entries))\n",
    "    return summary_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entries = get_data_in_list(path = \"sales_conversations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"kabita-choudhary/finetuned-bart-for-conversation-summary\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_1 = AutoTokenizer.from_pretrained(\"kabita-choudhary/finetuned-bart-for-conversation-summary\")\n",
    "model_1 = AutoModelForSeq2SeqLM.from_pretrained(\"kabita-choudhary/finetuned-bart-for-conversation-summary\").to(device)\n",
    "print(model_1.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed: 100%|██████████| 550/550 [04:53<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "finetuned_bart_summary_list = get_summary_list(data = data_entries, tokenizer = tokenizer_1, model = model_1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"utrobinmv/t5_summary_en_ru_zh_base_2048\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65100\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"utrobinmv/t5_summary_en_ru_zh_base_2048\")\n",
    "model_2 = AutoModelForSeq2SeqLM.from_pretrained(\"utrobinmv/t5_summary_en_ru_zh_base_2048\").to(device)\n",
    "print(model_2.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed: 100%|██████████| 550/550 [05:08<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t5_summary_list = get_summary_list(data = data_entries, tokenizer = tokenizer_2, model = model_2.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer_3 = AutoTokenizer.from_pretrained(\"Nexusflow/Athene-V2-Chat\")\n",
    "# model_3 = AutoModelForCausalLM.from_pretrained(\"Nexusflow/Athene-V2-Chat\").to(device)\n",
    "# print(model_3.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_summary_list = get_summary_list(data = data_entries, tokenizer = tokenizer_3, model = model_3.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"finetuned_bart\": finetuned_bart_summary_list,\n",
    "    \"T5\": t5_summary_list,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to output_summary_models.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"output_summary_models.csv\"  \n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"DataFrame saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer is interested in buying a new smartphone, a laptop and a gaming console. Salesman will help him to choose the right one. Customer is considering upgrading his company's server. Customer wants to buy a new smartwatch and a new printer for his home office.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['finetuned_bart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Index', 'label'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"labels.csv\")\n",
    "print(df.columns)\n",
    "df.dropna(inplace=True)\n",
    "ls = df[\"label\"].tolist()\n",
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to chat_summary_labels.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"chat_summary_labels.csv\"  \n",
    "df_1 = pd.read_csv(\"output_summary_models.csv\")\n",
    "df_1[\"label\"] = ls\n",
    "df_1.to_csv(csv_file, index=False)\n",
    "print(f\"DataFrame saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
